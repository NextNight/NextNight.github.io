<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name=referrer content=never>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Match-文本数据操作 | Kala</title>
  <meta name="description" content="这里主要是记录文本相关的比赛中积累的代码片段和操作，量变产生质变，每一次探索和积累都是一小步的成长，不求走的多快，多远，我一直在行走，在努力。  文本数据的处理主要是分词，去停用词(停用词中包括各种特殊符号以及对于构造向量无关的词)，向量化（词袋模型，词嵌入），词嵌入涉及到的词向量的训练。得到向量化的数据之后基本就同结构化数据一样操作了。 12# 导入数据，方便后续操作,数据其中一列为sente">
<meta name="keywords" content="文本处理">
<meta property="og:type" content="article">
<meta property="og:title" content="Match-文本数据操作">
<meta property="og:url" content="http://nextnight.github.io/2018/09/30/Match-文本数据操作/index.html">
<meta property="og:site_name" content="Kala">
<meta property="og:description" content="这里主要是记录文本相关的比赛中积累的代码片段和操作，量变产生质变，每一次探索和积累都是一小步的成长，不求走的多快，多远，我一直在行走，在努力。  文本数据的处理主要是分词，去停用词(停用词中包括各种特殊符号以及对于构造向量无关的词)，向量化（词袋模型，词嵌入），词嵌入涉及到的词向量的训练。得到向量化的数据之后基本就同结构化数据一样操作了。 12# 导入数据，方便后续操作,数据其中一列为sente">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-09-30T10:04:23.249Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Match-文本数据操作">
<meta name="twitter:description" content="这里主要是记录文本相关的比赛中积累的代码片段和操作，量变产生质变，每一次探索和积累都是一小步的成长，不求走的多快，多远，我一直在行走，在努力。  文本数据的处理主要是分词，去停用词(停用词中包括各种特殊符号以及对于构造向量无关的词)，向量化（词袋模型，词嵌入），词嵌入涉及到的词向量的训练。得到向量化的数据之后基本就同结构化数据一样操作了。 12# 导入数据，方便后续操作,数据其中一列为sente">
  <!-- Canonical links -->
  <link rel="canonical" href="http://nextnight.github.io/2018/09/30/Match-文本数据操作/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Kala" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  <!-- font-awesome CSS -->
  <!-- <link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
  <link rel="stylesheet" href="/css/style.css">
  
    
        <link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">
    
    

  <!--定不加载条  -->
  <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
  <link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
  <style>
      .pace .pace-progress {
          background: #1E92FB; /*进度条颜色*/
          height: 2px;
      }
      .pace .pace-progress-inner {
           box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
      }
      .pace .pace-activity {
          border-top-color: #1E92FB;    /*上边框颜色*/
          border-left-color: #1E92FB;    /*左边框颜色*/
      }
  </style>
  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/love.js"></script>
  <!-- MathJax -->
  <script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)'],['\\','\\']]}
      });
  </script>
</head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/NextNight" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">Kala</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">DL &amp; ML</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Beijing, china</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="Search" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="Type something..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav">
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">Home</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">Archives</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">Categories</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">Tags</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">Repository</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-books">
          <a href="/books">
            
            <i class="icon icon-book-fill"></i>
            
            <span class="menu-title">Books</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">Links</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-about active">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">About</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">Board</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p style="text-align:left;font-family:cursive；color:#c75079e6">物来顺应<br/>未来不迎<br/>当时不杂<br/>既过不恋!<br/></p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/LeetCode/">LeetCode</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML/">ML</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ML/NLP/">NLP</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Match/">Match</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Match/NLP/">NLP</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Math/">Math</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">4</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Numpy/">Numpy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Pandas/">Pandas</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Test/">Test</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/class1/">class1</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/class1/class2/">class2</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/凸优化/">凸优化</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/概率图模型/">概率图模型</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Tags</h3>
    <div class="widget-body">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Array/">Array</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BayesNetWork/">BayesNetWork</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRF/">CRF</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HMM/">HMM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jupyter/">Jupyter</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MLE/">MLE</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Numpy/">Numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pandas/">Pandas</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test/">Test</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/">matplotlib</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/svm/">svm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tag2/">tag2</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tg1/">tg1</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/决策树/">决策树</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/凸优化/">凸优化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分类推荐/">分类推荐</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分词/">分词</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/向量化/">向量化</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/支持向量机/">支持向量机</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文本分类/">文本分类</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文本处理/">文本处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/条件随机场/">条件随机场</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/极大似然估计/">极大似然估计</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/泰勒展式/">泰勒展式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/矩阵分解/">矩阵分解</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贝叶斯网络/">贝叶斯网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/逻辑回归/">逻辑回归</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/Array/" style="font-size: 13px;">Array</a> <a href="/tags/BayesNetWork/" style="font-size: 13px;">BayesNetWork</a> <a href="/tags/CRF/" style="font-size: 13px;">CRF</a> <a href="/tags/HMM/" style="font-size: 13px;">HMM</a> <a href="/tags/Jupyter/" style="font-size: 13px;">Jupyter</a> <a href="/tags/MLE/" style="font-size: 13px;">MLE</a> <a href="/tags/Numpy/" style="font-size: 13px;">Numpy</a> <a href="/tags/Pandas/" style="font-size: 13px;">Pandas</a> <a href="/tags/Python/" style="font-size: 14px;">Python</a> <a href="/tags/Test/" style="font-size: 13px;">Test</a> <a href="/tags/matplotlib/" style="font-size: 13px;">matplotlib</a> <a href="/tags/svm/" style="font-size: 13px;">svm</a> <a href="/tags/tag2/" style="font-size: 13px;">tag2</a> <a href="/tags/tg1/" style="font-size: 13px;">tg1</a> <a href="/tags/决策树/" style="font-size: 13px;">决策树</a> <a href="/tags/凸优化/" style="font-size: 13px;">凸优化</a> <a href="/tags/分类推荐/" style="font-size: 13px;">分类推荐</a> <a href="/tags/分词/" style="font-size: 13px;">分词</a> <a href="/tags/向量化/" style="font-size: 13px;">向量化</a> <a href="/tags/支持向量机/" style="font-size: 13px;">支持向量机</a> <a href="/tags/数据结构/" style="font-size: 13px;">数据结构</a> <a href="/tags/文本分类/" style="font-size: 13.5px;">文本分类</a> <a href="/tags/文本处理/" style="font-size: 13px;">文本处理</a> <a href="/tags/条件随机场/" style="font-size: 13px;">条件随机场</a> <a href="/tags/极大似然估计/" style="font-size: 13px;">极大似然估计</a> <a href="/tags/泰勒展式/" style="font-size: 13px;">泰勒展式</a> <a href="/tags/矩阵分解/" style="font-size: 13px;">矩阵分解</a> <a href="/tags/算法/" style="font-size: 13px;">算法</a> <a href="/tags/贝叶斯网络/" style="font-size: 13px;">贝叶斯网络</a> <a href="/tags/逻辑回归/" style="font-size: 13px;">逻辑回归</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">Archive</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Match/">Match</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/Match/NLP/">NLP</a>
              </p>
              <p class="item-title">
                <a href="/2018/09/30/Match-文本数据操作/" class="title">Match-文本数据操作</a>
              </p>
              <p class="item-date">
                <time datetime="2018-09-30T03:58:57.000Z" itemprop="datePublished">2018-09-30</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/class1/">class1</a><i class="icon icon-angle-right"></i><a class="category-link" href="/categories/class1/class2/">class2</a>
              </p>
              <p class="item-title">
                <a href="/2018/09/29/SNA-社交网络分析/" class="title">SNA-社交网络分析</a>
              </p>
              <p class="item-date">
                <time datetime="2018-09-29T07:32:02.000Z" itemprop="datePublished">2018-09-29</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/ML/">ML</a>
              </p>
              <p class="item-title">
                <a href="/2018/09/29/ML-DTree决策树/" class="title">ML-DTree决策树</a>
              </p>
              <p class="item-date">
                <time datetime="2018-09-29T07:16:44.000Z" itemprop="datePublished">2018-09-29</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/ML/">ML</a>
              </p>
              <p class="item-title">
                <a href="/2018/09/29/ML-Svm支持向量机/" class="title">ML-Svm支持向量机</a>
              </p>
              <p class="item-date">
                <time datetime="2018-09-29T07:15:10.000Z" itemprop="datePublished">2018-09-29</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/ML/">ML</a>
              </p>
              <p class="item-title">
                <a href="/2018/09/29/ML-Logistic回归/" class="title">ML-Logistic回归</a>
              </p>
              <p class="item-date">
                <time datetime="2018-09-29T07:13:53.000Z" itemprop="datePublished">2018-09-29</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<aside class="sidebar sidebar-toc collapse" id="collapseToc" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    <nav id="toc" class="article-toc">
      <h3 class="toc-title">Catalogue</h3>
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、数据查看"><span class="toc-number">1.</span> <span class="toc-text">1、数据查看</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、加载停用词"><span class="toc-number">2.</span> <span class="toc-text">2、加载停用词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3、分词去停用词"><span class="toc-number">3.</span> <span class="toc-text">3、分词去停用词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4、多类别共现词"><span class="toc-number">4.</span> <span class="toc-text">4、多类别共现词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5、Tf-Idf向量化"><span class="toc-number">5.</span> <span class="toc-text">5、Tf-Idf向量化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1、sklearn中的tf-idf"><span class="toc-number">5.0.1.</span> <span class="toc-text">5.1、sklearn中的tf-idf</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2、Gensim中的tf-idf"><span class="toc-number">5.0.2.</span> <span class="toc-text">5.2、Gensim中的tf-idf</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6、LSA向量化"><span class="toc-number">6.</span> <span class="toc-text">6、LSA向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7、LDA向量化"><span class="toc-number">7.</span> <span class="toc-text">7、LDA向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8、Word2vec词向量"><span class="toc-number">8.</span> <span class="toc-text">8、Word2vec词向量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1、Gensim-word2vec训练词向量"><span class="toc-number">8.0.1.</span> <span class="toc-text">8.1、Gensim.word2vec训练词向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-2、同时训练多个窗口的词向量"><span class="toc-number">8.0.2.</span> <span class="toc-text">8.2、同时训练多个窗口的词向量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-3、构建词向量字典"><span class="toc-number">8.0.3.</span> <span class="toc-text">8.3、构建词向量字典</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-4、词向量构建文档"><span class="toc-number">8.0.4.</span> <span class="toc-text">8.4、词向量构建文档</span></a></li></ol></li></ol></li></ol>
    </nav>
  </div>
</aside>

<main class="main" role="main">
  <div class="content">
  <article id="post-Match-文本数据操作" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
        
  
    <h1 class="article-title" itemprop="name">
      Match-文本数据操作
    </h1>
  

      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2018/09/30/Match-文本数据操作/" class="article-date">
	  <time datetime="2018-09-30T03:58:57.000Z" itemprop="datePublished">2018-09-30</time>
	</a>
</span>
        
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/Match/">Match</a>►<a class="article-category-link" href="/categories/Match/NLP/">NLP</a>
  </span>

        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link" href="/tags/文本处理/">文本处理</a>
  </span>


        

        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2018/09/30/Match-文本数据操作/#comments" class="article-comment-link">Comments</a></span>
        
      </div>
    </div>
    <div class="article-entry markdown-body" itemprop="articleBody">
      
        <blockquote>
<p>这里主要是记录文本相关的比赛中积累的代码片段和操作，量变产生质变，每一次探索和积累都是一小步的成长，不求走的多快，多远，我一直在行走，在努力。</p>
</blockquote>
<p>文本数据的处理主要是<code>分词</code>，<code>去停用词</code>(停用词中包括各种特殊符号以及对于构造向量无关的词)，<code>向量化</code>（词袋模型，词嵌入），词嵌入涉及到的词向量的训练。得到向量化的数据之后基本就同结构化数据一样操作了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入数据，方便后续操作,数据其中一列为sentence,即文本内容</span></span><br><span class="line">train = pd.read_csv(<span class="string">"data/train.csv"</span>,index=<span class="keyword">None</span>, encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure>
<h2 id="1、数据查看"><a href="#1、数据查看" class="headerlink" title="1、数据查看"></a>1、数据查看</h2><blockquote>
<p>文本数据一般会查看数据的长度，确定是长文本还是短文本，我们还可以分析文本对于固定模式的首尾相同的数据进行首尾数据额删除，不过至于删除多少需要测试，首尾多长的文本会是相同的内容，可以采用编辑距离计算一个平均距离，选取不同的长度分别得到平均距离，可以最终选择一个平均距离最短对应的长度作为我们要删除的文本长度。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_date</span><span class="params">()</span>：</span></span><br><span class="line"><span class="function">  # 文本为字符串</span></span><br><span class="line">  train['len'] = train['sentence'].apply(lambda x:len(x))</span><br><span class="line">  train[<span class="string">'len'</span>].describe()</span><br><span class="line">  <span class="comment"># 文本已经切分</span></span><br><span class="line">  train[<span class="string">'len'</span>] = train[<span class="string">'sentence'</span>].apply(<span class="keyword">lambda</span> x:len(x.split(<span class="string">' '</span>)))</span><br><span class="line">  train[<span class="string">'len'</span>].describe()</span><br><span class="line">  <span class="comment"># 文章长度分箱</span></span><br><span class="line">  bins = [<span class="number">0</span>, <span class="number">100</span>, <span class="number">500</span>, <span class="number">1000</span>, <span class="number">2000</span>, <span class="number">5000</span>, <span class="number">100000</span>]</span><br><span class="line">  cats = pd.cut(train[<span class="string">'len'</span>], bins=bins,labels=<span class="keyword">None</span>)</span><br><span class="line">  print(pd.value_counts(cats))</span><br></pre></td></tr></table></figure>
<h2 id="2、加载停用词"><a href="#2、加载停用词" class="headerlink" title="2、加载停用词"></a>2、加载停用词</h2><blockquote>
<p>文本处理的基本操作，这里可以直接将得到的停用词列表作为全局变量，否则对每条数据分词的时候都需要读取一遍。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stop_words_list</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    @ func 读取停用词列表</span></span><br><span class="line"><span class="string">    @ param path:停用词路径</span></span><br><span class="line"><span class="string">    停用词为每一行一个词存储</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    stop_words = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> open(path, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>).readlines()]</span><br><span class="line">    <span class="keyword">return</span> stop_words</span><br></pre></td></tr></table></figure>
<h2 id="3、分词去停用词"><a href="#3、分词去停用词" class="headerlink" title="3、分词去停用词"></a>3、分词去停用词</h2><blockquote>
<p>遍历所有数据，对每一条进行如下的分词去停用词操作。<code>df[&#39;senctence&#39;].apply(lambda x: seg_sentence_all(x))</code></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">seg_sentence_all</span><span class="params">(sentence)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对句子进行分词,去停用词</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    path = <span class="string">"data/stop_word_all.txt"</span></span><br><span class="line">    sentence_seged = jieba.cut(sentence.strip())</span><br><span class="line">    stop_words = stop_words_list(path)  <span class="comment"># 这里加载停用词的路径</span></span><br><span class="line">    cut_s = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sentence_seged:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stop_words:</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">'\t'</span>:</span><br><span class="line">                str += word.strip()</span><br><span class="line">                str += <span class="string">' '</span></span><br><span class="line">    <span class="keyword">return</span> str.strip()</span><br></pre></td></tr></table></figure>
<h2 id="4、多类别共现词"><a href="#4、多类别共现词" class="headerlink" title="4、多类别共现词"></a>4、多类别共现词</h2><blockquote>
<p>在文本分类中，多个类别中频繁多次出现的词可能是停用词，也可能是标点符号，对于脱敏数据，我们无法查看到原始数据，无法确定停用词的时候可以使用如下方法来找出一部分贡献词作为停用词。</p>
<p>同样可以对所有分词后的数据做词的交集，更加精确粗暴。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_stop_word</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 为每个类构建词袋</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'bowlist.csv'</span>):</span><br><span class="line">        column = <span class="string">'word_seg'</span></span><br><span class="line">        train = pd.read_csv(path_train, encoding=<span class="string">'utf-8'</span>, sep=<span class="string">','</span>)</span><br><span class="line">        bowlist = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> np.arange(<span class="number">1</span>, <span class="number">20</span>, <span class="number">1</span>):</span><br><span class="line">            st = train[train[<span class="string">'class'</span>] == i]</span><br><span class="line">            cv = CountVectorizer(ngram_range=(<span class="number">1</span>, <span class="number">1</span>), lowercase=<span class="keyword">False</span>, max_df=<span class="number">0.9</span>, min_df=<span class="number">2</span>)</span><br><span class="line">            cv.fit(st[column].values)</span><br><span class="line">            vocal = cv.get_feature_names()</span><br><span class="line">            vst = set(vocal)</span><br><span class="line">            bowlist.extend(list(vst))</span><br><span class="line">        df = pd.DataFrame(bowlist)</span><br><span class="line">        df.to_csv(<span class="string">"bowlist.csv"</span>, index=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment"># 查看在多个类中出现的词</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        df = pd.read_csv(<span class="string">"bowlist.csv"</span>)</span><br><span class="line">        print(df)</span><br><span class="line">    dt = pd.DataFrame(df[<span class="string">'0'</span>].value_counts().reset_index())</span><br><span class="line">    dt.columns = [<span class="string">'word'</span>, <span class="string">'count'</span>]</span><br><span class="line">    <span class="comment"># 19个类别，如果在多个类别都出现则可作为停用词</span></span><br><span class="line">    dt[dt[<span class="string">'count'</span>] &gt; <span class="number">12</span>][<span class="string">'word'</span>].to_csv(<span class="string">'stop_word.csv'</span>, encoding=<span class="string">'utf-8'</span>, index=<span class="keyword">None</span>, header=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<h2 id="5、Tf-Idf向量化"><a href="#5、Tf-Idf向量化" class="headerlink" title="5、Tf-Idf向量化"></a>5、Tf-Idf向量化</h2><blockquote>
<p>TF-Idf传统文本处理的常用向量化操作 【他表示的是一个词的重要程度】。TF:表示词频，一个词在一篇文档中出现的频率，越大表示越重要，越具备代表性。但是它同时在很多文档中都出现了，那么他就不具备代表性。所有重要性与频率正比，与出现的文档数成反比，因此使用逆文档频率Idf表示降低频率的影响。Idf=lg(N/n)N:表示文档总数，n表示出现该词的文档数。TF=count/len(doc),count:词在文档doc出现次数,len(doc):表示文档词数。</p>
</blockquote>
<h4 id="5-1、sklearn中的tf-idf"><a href="#5-1、sklearn中的tf-idf" class="headerlink" title="5.1、sklearn中的tf-idf"></a>5.1、sklearn中的tf-idf</h4><blockquote>
<p>重要的参数：</p>
<pre><code>- stop_words：可以传递一个停用词列表到这用于构建向量的时候去除停用词

- ngram_range:也就是n-gram,N元词型合适的n-gram对结果有很大的帮助

- lowercase：False,强转小写，默认True，但是对于中文会报错。
</code></pre></blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TfidfVec</span><span class="params">(dt_train, dt_test)</span>:</span></span><br><span class="line">    Tfidf = TfidfVectorizer(min_df=<span class="number">2</span>, max_df=<span class="number">0.9</span>, </span><br><span class="line">                            use_idf=<span class="number">1</span>, smooth_idf=<span class="number">1</span>, </span><br><span class="line">                            sublinear_tf=<span class="number">1</span>, ngram_range=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">                            stop_words=load_stopws(),lowercase=<span class="keyword">False</span>)</span><br><span class="line">    Tfidf.fit(dt_train[<span class="string">'article'</span>])</span><br><span class="line">    print(Tfidf.max_features)</span><br><span class="line">    train_word_vec = Tfidf.transform(dt_train[<span class="string">'article'</span>])</span><br><span class="line">    test_word_vec = Tfidf.transform(dt_test[<span class="string">'article'</span>])</span><br><span class="line">    <span class="keyword">return</span> train_word_vec, test_word_vec</span><br></pre></td></tr></table></figure>
<h4 id="5-2、Gensim中的tf-idf"><a href="#5-2、Gensim中的tf-idf" class="headerlink" title="5.2、Gensim中的tf-idf"></a>5.2、Gensim中的tf-idf</h4><blockquote>
<p>Gensim是一个非常常用的NLP库，里面包含各种在官方基础上封装的库翻遍我们使用，包括常用的Word2Vec,LDA…</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gensim_Tfidf</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 生成语料</span></span><br><span class="line">    sentences = [<span class="string">"我喜欢北京三点的太阳"</span>, <span class="string">"番茄炒西红柿是我的最爱"</span>, <span class="string">"我不喜欢今天雾霾的西安"</span>]</span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> sentences:</span><br><span class="line">        words.append(list(jieba.cut(doc)))</span><br><span class="line">    print(words)</span><br><span class="line">    <span class="comment"># 生成词典</span></span><br><span class="line">    dic = corpora.Dictionary(words)</span><br><span class="line">    <span class="comment"># 生成语料库(每一个文档生成(词,出现的次数))的列表=即一个词频向量的稀疏表示</span></span><br><span class="line">    cps = [dic.doc2bow(text) <span class="keyword">for</span> text <span class="keyword">in</span> words]</span><br><span class="line">         <span class="comment"># 训练tfidf模型</span></span><br><span class="line">    tfidf = TfidfModel(corpus=cps)</span><br><span class="line">    <span class="comment"># 转换词频向量为tfidf向量</span></span><br><span class="line">    cps_tfidf = tfidf[cps]</span><br><span class="line">        <span class="keyword">return</span> cps_tfidf</span><br></pre></td></tr></table></figure>
<h2 id="6、LSA向量化"><a href="#6、LSA向量化" class="headerlink" title="6、LSA向量化"></a>6、LSA向量化</h2><blockquote>
<p>LSA,也可以叫做LSI,浅语义模型，是一种基于TF或者TF-IDF的降维手段，同时也是描述词语之间的语义关系的语义模型，它认为词和文档的共现矩阵当中存在着词之间语义关系，他们具有一定的相似性，构建词-文档的共现矩阵(通常是词频矩阵或TF-IDF权重矩阵)在进行SVD矩阵分解，在这个稠密的低维空间中。任意两个行向量即两个词的向量求相似度可以表示语义关系。</p>
<p>Gensim中已经集成LSA的模型可以直接调用。直接将cps或者cps_tfidf喂给LsiModel就可以得到降维后的数据，可用与分类，聚类。做相似度计算。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_lsi</span><span class="params">(cps, dic)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    LSI：浅语义分析</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    print(<span class="string">"\n=================LSI================="</span>)</span><br><span class="line">    lsi = LsiModel(corpus=cps, num_topics=<span class="number">2</span>, id2word=dic)</span><br><span class="line">    <span class="comment"># 输出训练得到的主题</span></span><br><span class="line">    tp = lsi.print_topics(num_topics=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 查看每个文档的LSI主题分布</span></span><br><span class="line">    cps_lsi = lsi[cps]</span><br><span class="line">        <span class="keyword">return</span> cps_lsi</span><br></pre></td></tr></table></figure>
<h2 id="7、LDA向量化"><a href="#7、LDA向量化" class="headerlink" title="7、LDA向量化"></a>7、LDA向量化</h2><blockquote>
<p>LDA,又称主题模型，它认为在词和文档之间存在摸个隐变量 [主题] ，每个主题由多个词构成且每个词有一定的概率出现。而一篇文档可以由多个主题构成，且每个主题同样有一定的概率。那么如何得到一篇文档呢?我们知道这篇文档的主题分布，只需要以这个概率分布不断的去选择主题，再分别为每个主题按照主题-词的概率分布去选择词，迭代稳定后就可以的得到这篇文档。所以说我们可以将一篇用词表示的文档，用主题的概率分布来表示。表示之后的文档向量是一个稠密的低维向量，包含了某种语义联系，同时又进行了降维。</p>
<p>Gensim中同样进行了LDA的实现，同上，将cps或者cps_tfidf喂给LdaModel就可以得到降维后的数据。可用与分类，聚类，做相似度计算。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_lda</span><span class="params">(cps,dic)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    LDA:主题模型</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    print(<span class="string">"\n=================LDA================="</span>)</span><br><span class="line">    lda = LdaModel(corpus=cps, num_topics=<span class="number">2</span>, id2word=dic)</span><br><span class="line">    <span class="comment"># 输出五个主题</span></span><br><span class="line">    tp = lda.print_topics(num_topics=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出每个文档的主题</span></span><br><span class="line">    cps_lda = lda[cps]</span><br><span class="line">    <span class="keyword">return</span> cps_lda</span><br></pre></td></tr></table></figure>
<h2 id="8、Word2vec词向量"><a href="#8、Word2vec词向量" class="headerlink" title="8、Word2vec词向量"></a>8、Word2vec词向量</h2><blockquote>
<p>词向量表示是的是一个词的向量化表示，one-hot，tf,tf-idf都是一种词向量表示法，而word2vec也是一种词向量表示法，他通过训练一个词的上下文表示以一个词的概率这种深度学习分类模型来得到一组隐层权重来表示一个词，这个权重就是词向量它能够表示更多的语义信息和语序信息。</p>
<p>以下是Gensim包中的word2vec词向量训练，主要参数</p>
<ul>
<li><p>windows:上下文词的个数</p>
</li>
<li><p>size:需要训练的词向量的维度</p>
</li>
</ul>
<p>影响词向量的主要参数就是这两个，关于word2vec和其他参数，其他地方在做介绍。</p>
</blockquote>
<h4 id="8-1、Gensim-word2vec训练词向量"><a href="#8-1、Gensim-word2vec训练词向量" class="headerlink" title="8.1、Gensim.word2vec训练词向量"></a>8.1、Gensim.word2vec训练词向量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> Word2Vec</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word2vec_train</span><span class="params">()</span>:</span></span><br><span class="line">      <span class="string">"""训练词向量"""</span></span><br><span class="line">    train = pd.read_csv(path_train, encoding=<span class="string">'utf-8'</span>, sep=<span class="string">','</span>)</span><br><span class="line">        <span class="comment"># train['word_seg']表示分词后的列</span></span><br><span class="line">    model = Word2Vec(train[<span class="string">'word_seg'</span>].values, window=<span class="number">5</span>, sg=<span class="number">0</span>, size=<span class="number">200</span>, min_count=<span class="number">1</span>,</span><br><span class="line">                     negative=<span class="number">3</span>, sample=<span class="number">0.001</span>, hs=<span class="number">1</span>, workers=<span class="number">4</span>,cbow_mean=<span class="number">1</span>)</span><br><span class="line">    model.wv.save_word2vec_format(<span class="string">"model.ve"</span>, binary=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以通过修改以上两个参数，得到不同的词向量选择质量高的，或者如下同时训练多个词向量</p>
</blockquote>
<h4 id="8-2、同时训练多个窗口的词向量"><a href="#8-2、同时训练多个窗口的词向量" class="headerlink" title="8.2、同时训练多个窗口的词向量"></a>8.2、同时训练多个窗口的词向量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]:</span><br><span class="line">    model = Word2Vec(data_all, window=i, sg=<span class="number">0</span>, size=<span class="number">100</span>, min_count=<span class="number">1</span>, negative=<span class="number">3</span>,</span><br><span class="line">                     sample=<span class="number">0.001</span>, hs=<span class="number">1</span>, workers=<span class="number">4</span>,cbow_mean=<span class="number">1</span>)</span><br><span class="line">    model.save(os.path.join(mc.data_path, <span class="string">'model.model'</span>))</span><br><span class="line">    model.wv.save_word2vec_format(os.path.join(mc.data_path, <span class="string">"model.ve"</span> + str(i)), binary=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="8-3、构建词向量字典"><a href="#8-3、构建词向量字典" class="headerlink" title="8.3、构建词向量字典"></a>8.3、构建词向量字典</h4><blockquote>
<p>训练得到的词向量是一个文件，第一行有词的个数，第二行起每一行第一列是词，其他列对应的是词向量，以空格分割，要想把数据中的词对应上还需要建立词典。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_embeddings_dict</span><span class="params">()</span>:</span></span><br><span class="line">    embeddings_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> open(os.path.join(mc.data_path, <span class="string">'model.ve'</span>), encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">            values = line.split(<span class="string">' '</span>)</span><br><span class="line">            coefs = np.asarray(values[<span class="number">1</span>:], dtype=<span class="string">'float64'</span>)</span><br><span class="line">            embeddings_dict[values[<span class="number">0</span>]] = coefs</span><br><span class="line">    <span class="keyword">return</span> embeddings_dict</span><br></pre></td></tr></table></figure>
<h4 id="8-4、词向量构建文档"><a href="#8-4、词向量构建文档" class="headerlink" title="8.4、词向量构建文档"></a>8.4、词向量构建文档</h4><blockquote>
<p>一条数据寄一个文档，一个文档有10个词，每一个词是一个100维的词向量，那么这个文档就可以用word_count*100的矩阵表示。当然我们也可以通过把每一个词的词向量加和求平均值，这样一篇文档就是一个100维的向量了。</p>
</blockquote>
<ul>
<li>文档向量=词向量加和平均</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">word_embedding_vector</span><span class="params">(s, embeddings_dict)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    词嵌入构建句子向量</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    svt = np.zeros(<span class="number">100</span>, dtype=<span class="string">'float64'</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> s.split(<span class="string">' '</span>):  <span class="comment"># ==x.split(' ')</span></span><br><span class="line">        word_v = embeddings_dict.get(word)</span><br><span class="line">        <span class="keyword">if</span> word_v <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            svt += word_v</span><br><span class="line">    <span class="keyword">return</span> svt</span><br></pre></td></tr></table></figure>
<ul>
<li>文档向量=文档中所有词的词向量组成的矩阵</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">EMBEDDING_DIM = <span class="number">300</span></span><br><span class="line">nb_words = min(MAX_NB_WORDS,len(word_index))</span><br><span class="line">word_embedding_matrix = np.zeros((nb_words + <span class="number">1</span>, EMBEDDING_DIM))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    <span class="keyword">if</span> i &gt; MAX_NB_WORDS:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    embedding_vector = embeddings_index.get(str(word))</span><br><span class="line">    <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">        word_embedding_matrix[i] = embedding_vector</span><br></pre></td></tr></table></figure>
<blockquote>
<p>对每一个文档获取如上的矩阵，那么着呢哥哥训练集，就是一个三维额矩阵。Text-cnn采用的就是这种结构。</p>
</blockquote>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong align="center">If not me,who? If not now.when?</strong>
      <!-- <a href="http://nextnight.github.io/2018/09/30/Match-文本数据操作/" title="Match-文本数据操作" target="_blank" rel="external">http://nextnight.github.io/2018/09/30/Match-文本数据操作/</a> -->
    </li>
    
    
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/NextNight" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/NextNight" target="_blank"><span class="text-dark">Kala</span><small class="ml-1x">DL &amp; ML</small></a></h3>
        <div>If not me,who? If not now.when?</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
       
    <div id="vcomments"></div>

    
    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    
    <li class="next">
      <a href="/2018/09/29/SNA-社交网络分析/" title="SNA-社交网络分析"><span>Older&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
    <li class="toggle-toc">
      <a class="toggle-btn collapsed" data-toggle="collapse" href="#collapseToc" aria-expanded="false" title="Catalogue" role="button">
        <span>[&nbsp;</span><span>Catalogue</span>
        <i class="text-collapsed icon icon-anchor"></i>
        <i class="text-in icon icon-close"></i>
        <span>]</span>
      </a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning" data-toggle="modal" data-target="#donateModal"><span>$</span></button>
  <!-- <div class="wave-icon wave-icon-danger btn-donate" data-toggle="modal" data-target="#donateModal">
    <div class="wave-circle"><span class="icon"><i class="icon icon-bill"></i></span></div>
  </div> -->
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-small modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content donate">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-head">
            <p>Maybe you could buy me a cup of coffee.</p>
          </div>
          <div class="tab-content">
            <div role="tabpanel" class="tab-pane fade active in" id="alipay">
              <div class="donate-payimg">
                <img src="/images/donate/xxx.png" alt="Scan Qrcode" title="Scan" />
              </div>
              <p class="text-muted mv">Scan this qrcode</p>
              <p class="text-grey">Open alipay app scan this qrcode, buy me a coffee!</p>
            </div>
            <div role="tabpanel" class="tab-pane fade" id="wechatpay">
              <div class="donate-payimg">
                <img src="/images/donate/xxx.png" alt="Scan Qrcode" title="Scan" />
              </div>
              <p class="text-muted mv">Scan this qrcode</p>
              <p class="text-grey">Open wechat app scan this qrcode, buy me a coffee!</p>
            </div>
          </div>
          <div class="donate-footer">
            <ul class="nav nav-tabs nav-justified" role="tablist">
              <li role="presentation" class="active">
                <a href="#alipay" id="alipay-tab" role="tab" data-toggle="tab" aria-controls="alipay" aria-expanded="true"><i class="icon icon-alipay"></i> alipay</a>
              </li>
              <li role="presentation" class="">
                <a href="#wechatpay" role="tab" id="wechatpay-tab" data-toggle="tab" aria-controls="wechatpay" aria-expanded="false"><i class="icon icon-wepay"></i> wechat payment</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script src="/js/plugin.min.js"></script>
<script src="/js/application.js"></script>
  
    
    
    
        <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>
    
    
    
        


    
    
        
    
   <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
   <script src="//cdn.jsdelivr.net/npm/valine"></script>
   <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
     var meta = 'nick,mail,link';
     meta = meta.split(',').filter(function (item) {
       return GUEST.indexOf(item)>-1;
     });
     new Valine({
         el: '#vcomments' ,
         verify: false,
         notify: false,
         appId: '',
         appKey: '',
         placeholder: 'Just go go',
         avatar:'mm',
         meta:meta,
         pageSize:'10' || 10,
         visitor: false
     });
   </script>

    

    
    



</body>
</html>