{"meta":{"title":"Kala","subtitle":"Do Best Kala","description":"DeepLearn MeachineLearn","author":"Best Kala","url":"http://nextnight.github.io"},"pages":[{"title":"关于","date":"2018-09-29T08:24:57.543Z","updated":"2018-09-29T08:24:57.543Z","comments":false,"path":"about/index.html","permalink":"http://nextnight.github.io/about/index.html","excerpt":"","text":""},{"title":"书单","date":"2018-09-28T02:12:26.198Z","updated":"2018-07-27T09:13:16.681Z","comments":false,"path":"books/index.html","permalink":"http://nextnight.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-09-28T02:12:26.198Z","updated":"2018-07-27T09:13:16.681Z","comments":false,"path":"categories/index.html","permalink":"http://nextnight.github.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-09-28T02:12:26.198Z","updated":"2018-07-27T09:13:16.682Z","comments":false,"path":"repository/index.html","permalink":"http://nextnight.github.io/repository/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-29T08:24:35.226Z","updated":"2018-09-29T08:24:35.226Z","comments":false,"path":"tags/index.html","permalink":"http://nextnight.github.io/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-09-28T02:12:26.198Z","updated":"2018-07-27T09:13:16.682Z","comments":true,"path":"links/index.html","permalink":"http://nextnight.github.io/links/index.html","excerpt":"","text":""}],"posts":[{"title":"SNA-社交网络分析","slug":"SNA-社交网络分析","date":"2018-09-29T07:32:02.000Z","updated":"2018-09-29T07:32:02.063Z","comments":true,"path":"2018/09/29/SNA-社交网络分析/","link":"","permalink":"http://nextnight.github.io/2018/09/29/SNA-社交网络分析/","excerpt":"","text":"","categories":[{"name":"class1","slug":"class1","permalink":"http://nextnight.github.io/categories/class1/"},{"name":"class2","slug":"class1/class2","permalink":"http://nextnight.github.io/categories/class1/class2/"}],"tags":[{"name":"tg1","slug":"tg1","permalink":"http://nextnight.github.io/tags/tg1/"},{"name":"tag2","slug":"tag2","permalink":"http://nextnight.github.io/tags/tag2/"}]},{"title":"ML-DTree决策树","slug":"ML-DTree决策树","date":"2018-09-29T07:16:44.000Z","updated":"2018-09-29T07:18:02.425Z","comments":true,"path":"2018/09/29/ML-DTree决策树/","link":"","permalink":"http://nextnight.github.io/2018/09/29/ML-DTree决策树/","excerpt":"","text":"","categories":[{"name":"ML","slug":"ML","permalink":"http://nextnight.github.io/categories/ML/"}],"tags":[{"name":"决策树","slug":"决策树","permalink":"http://nextnight.github.io/tags/决策树/"}]},{"title":"ML-Svm支持向量机","slug":"ML-Svm支持向量机","date":"2018-09-29T07:15:10.000Z","updated":"2018-09-29T07:17:46.640Z","comments":true,"path":"2018/09/29/ML-Svm支持向量机/","link":"","permalink":"http://nextnight.github.io/2018/09/29/ML-Svm支持向量机/","excerpt":"","text":"","categories":[{"name":"ML","slug":"ML","permalink":"http://nextnight.github.io/categories/ML/"}],"tags":[{"name":"支持向量机","slug":"支持向量机","permalink":"http://nextnight.github.io/tags/支持向量机/"},{"name":"svm","slug":"svm","permalink":"http://nextnight.github.io/tags/svm/"}]},{"title":"ML-Logistic回归","slug":"ML-Logistic回归","date":"2018-09-29T07:13:53.000Z","updated":"2018-09-29T07:17:31.024Z","comments":true,"path":"2018/09/29/ML-Logistic回归/","link":"","permalink":"http://nextnight.github.io/2018/09/29/ML-Logistic回归/","excerpt":"","text":"","categories":[{"name":"ML","slug":"ML","permalink":"http://nextnight.github.io/categories/ML/"}],"tags":[{"name":"逻辑回归","slug":"逻辑回归","permalink":"http://nextnight.github.io/tags/逻辑回归/"}]},{"title":"Match-DaGuanCup","slug":"Match-DaGuanCup","date":"2018-09-29T07:02:57.000Z","updated":"2018-09-29T07:08:18.192Z","comments":true,"path":"2018/09/29/Match-DaGuanCup/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Match-DaGuanCup/","excerpt":"","text":"","categories":[{"name":"Match","slug":"Match","permalink":"http://nextnight.github.io/categories/Match/"}],"tags":[{"name":"文本分类","slug":"文本分类","permalink":"http://nextnight.github.io/tags/文本分类/"}]},{"title":"Match-LianTong","slug":"Match-LianTong","date":"2018-09-29T06:46:00.000Z","updated":"2018-09-29T07:08:03.400Z","comments":true,"path":"2018/09/29/Match-LianTong/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Match-LianTong/","excerpt":"","text":"","categories":[{"name":"Match","slug":"Match","permalink":"http://nextnight.github.io/categories/Match/"}],"tags":[{"name":"分类推荐","slug":"分类推荐","permalink":"http://nextnight.github.io/tags/分类推荐/"}]},{"title":"Match-YunYiCup","slug":"Match-Yunyicup","date":"2018-09-29T06:42:48.000Z","updated":"2018-09-29T07:07:08.749Z","comments":true,"path":"2018/09/29/Match-Yunyicup/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Match-Yunyicup/","excerpt":"","text":"","categories":[{"name":"Match","slug":"Match","permalink":"http://nextnight.github.io/categories/Match/"}],"tags":[{"name":"文本分类","slug":"文本分类","permalink":"http://nextnight.github.io/tags/文本分类/"}]},{"title":"Graph-BayesNetWork","slug":"Graph-BayesNetWork","date":"2018-09-29T06:40:58.000Z","updated":"2018-09-29T07:35:49.614Z","comments":true,"path":"2018/09/29/Graph-BayesNetWork/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Graph-BayesNetWork/","excerpt":"","text":"","categories":[{"name":"概率图模型","slug":"概率图模型","permalink":"http://nextnight.github.io/categories/概率图模型/"}],"tags":[{"name":"BayesNetWork","slug":"BayesNetWork","permalink":"http://nextnight.github.io/tags/BayesNetWork/"},{"name":"贝叶斯网络","slug":"贝叶斯网络","permalink":"http://nextnight.github.io/tags/贝叶斯网络/"}]},{"title":"Graph-CRF条件随机场","slug":"Graph-CRF条件随机场","date":"2018-09-29T06:30:53.000Z","updated":"2018-09-29T07:35:18.776Z","comments":true,"path":"2018/09/29/Graph-CRF条件随机场/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Graph-CRF条件随机场/","excerpt":"","text":"","categories":[{"name":"概率图模型","slug":"概率图模型","permalink":"http://nextnight.github.io/categories/概率图模型/"}],"tags":[{"name":"CRF","slug":"CRF","permalink":"http://nextnight.github.io/tags/CRF/"},{"name":"条件随机场","slug":"条件随机场","permalink":"http://nextnight.github.io/tags/条件随机场/"}]},{"title":"Graph-HMM隐马尔科夫","slug":"Graph-HMM隐马尔科夫","date":"2018-09-29T06:30:37.000Z","updated":"2018-09-29T07:34:54.564Z","comments":true,"path":"2018/09/29/Graph-HMM隐马尔科夫/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Graph-HMM隐马尔科夫/","excerpt":"","text":"","categories":[{"name":"概率图模型","slug":"概率图模型","permalink":"http://nextnight.github.io/categories/概率图模型/"}],"tags":[{"name":"HMM","slug":"HMM","permalink":"http://nextnight.github.io/tags/HMM/"}]},{"title":"Math-矩阵分解","slug":"Math-矩阵分解","date":"2018-09-29T06:27:30.000Z","updated":"2018-09-29T07:29:18.171Z","comments":true,"path":"2018/09/29/Math-矩阵分解/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Math-矩阵分解/","excerpt":"","text":"","categories":[{"name":"Math","slug":"Math","permalink":"http://nextnight.github.io/categories/Math/"}],"tags":[{"name":"矩阵分解","slug":"矩阵分解","permalink":"http://nextnight.github.io/tags/矩阵分解/"}]},{"title":"Math-凸优化问题","slug":"Math-凸优化问题","date":"2018-09-29T06:25:00.000Z","updated":"2018-09-29T07:18:50.840Z","comments":true,"path":"2018/09/29/Math-凸优化问题/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Math-凸优化问题/","excerpt":"","text":"","categories":[{"name":"凸优化","slug":"凸优化","permalink":"http://nextnight.github.io/categories/凸优化/"}],"tags":[{"name":"凸优化","slug":"凸优化","permalink":"http://nextnight.github.io/tags/凸优化/"}]},{"title":"Math-泰勒展式","slug":"Math-泰勒展式","date":"2018-09-29T06:21:53.000Z","updated":"2018-09-29T07:29:40.308Z","comments":true,"path":"2018/09/29/Math-泰勒展式/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Math-泰勒展式/","excerpt":"","text":"","categories":[{"name":"Math","slug":"Math","permalink":"http://nextnight.github.io/categories/Math/"}],"tags":[{"name":"泰勒展式","slug":"泰勒展式","permalink":"http://nextnight.github.io/tags/泰勒展式/"}]},{"title":"Math-极大似然估计","slug":"Math-极大似然估计","date":"2018-09-29T06:21:27.000Z","updated":"2018-09-29T07:18:26.798Z","comments":true,"path":"2018/09/29/Math-极大似然估计/","link":"","permalink":"http://nextnight.github.io/2018/09/29/Math-极大似然估计/","excerpt":"","text":"","categories":[{"name":"Math","slug":"Math","permalink":"http://nextnight.github.io/categories/Math/"}],"tags":[{"name":"MLE","slug":"MLE","permalink":"http://nextnight.github.io/tags/MLE/"},{"name":"极大似然估计","slug":"极大似然估计","permalink":"http://nextnight.github.io/tags/极大似然估计/"}]},{"title":"文本处理流程","slug":"文本处理流程","date":"2018-09-29T05:49:41.000Z","updated":"2018-09-29T06:57:26.303Z","comments":true,"path":"2018/09/29/文本处理流程/","link":"","permalink":"http://nextnight.github.io/2018/09/29/文本处理流程/","excerpt":"","text":"\b文本处理的流程文本–&gt;分词–&gt;向量化–&gt;建模 1、分词方法 分词是NLP的基础，无论是文档还是语句都是有基本的词构成，因此分词的好坏直接影响到文本的表示。 基本匹配分词 1234567此方法按照不同的扫描方式，逐个查找词库进行分词。根据扫描方式可细分为： 正向最大匹配 反向最大匹配 双向最大匹配 最小切分(即最短路径)总之就是各种不同的启发规则 全局切分+语言模型分词 1234567- 基本操作： 1、它首先切分出与词库匹配的所有可能的词， 2、再运用统计语言模型决定最优的切分结果。【一般采用viterbi算法寻找找最优的组合】- 优点： 1、在于可以解决分词中的歧义问题。- 示例： 对于文本串“南京市长江大桥”，首先进行词条检索(一般用Trie存储)，找到匹配的所有词条（南京，市，长江，大桥，南京市，长江大桥，市长，江大桥，江大，桥），以词网格(word lattices)形式表示，接着做路径搜索，基于统计语言模型(例如n-gram)找到最优路径，最后可能还需要命名实体识别。 以字构词 1234567891011121314151617181920- 基本操作： 1、将分词问题转化为了单个字的分类问题(序列标签)，为每一个字打上'B','I','E','S'五个标签中的一个。其中'B':一个词的开头，'I':一个词的中间，'E':一个词的结尾，'S':单个字成词。 2、通过统计信息得到每个字的标签的概率，然后采用'Viterbi算法'得到最优的结果。- 优点： 1、具有新词发现功能，准确率较高。- 实现： 1、'HMM分词', 2、'CRF分词', 3、'深度学习分词'- [1] 深度学习分词的流程： -1、将每一个字Lookup Table映射到一个固定长度的特征向量. -2、经过一个标准的神经网络：liner-sigmod-liner三层'同样得到每个字属于B,I,E,S四个Tag的概率'. -3、采用'Viterbi算法'求得最优结果.- [2] HMM分词 VS CRF分词 CRF：目前效果已经优于HMM，无论是新词发现还是实体识别，人名识别。 优点: 1、在于CRF既可以像最大熵模型一样加各种领域feature。 2、又避免了HMM的齐次马尔科夫假设。 2、语言模型： 语言模型是用来计算一句话生成概率的模型， 1、语言模型的演变[1.1] bayes: 12345- 定义：每个词出现的概率取决于前面所有的词- 公式：P(w_m) = p(w_m|w_&#123;m-1&#125;,w_&#123;m-2&#125;..w_1)- P(S)：P(S) = P(w_1)*p(w_2)...p(w_n),n为词或字个数,P(S)表示句子概率- 缺点：计算过于复杂，甚至难以计算- 简化：朴素贝叶斯，条件独立性假设 [1.2] n-gram：n元词型12345678910- 定义：衍生自HMM，它利用马尔科夫假设，认为句子中每个单词只与其前n–1个单词有关，即假设产生w_m这个词的条件概率只依赖于前n–1个词。其中n越大，模型可区别性越强，n越小，模型可靠性越高。- 公式：p(w_m) = p(w_m|w_&#123;m-n+1&#125;...,w_&#123;m-1&#125;))- P(S)：P(S) = P(w_1)*p(w_2)...p(w_n),n为词或字个数,P(S)表示句子概率- 优点： 1、简单有效，多元词型组合可以得到更丰富的信息 2、考虑了词的位置关系- 不足： 1、没有考虑到词语的相似性 2、没有考虑词法，语法，以及语义信息 3、仍然存在数据稀疏的问题 [1.3] ffnnlm：前馈神经网络语言模型1234- 定义：基于n-gram的语言模型，他将词\"w_m\"的前n-1个词p(w_&#123;m-n+1&#125;...p(w_&#123;m-1&#125;))映射到词向量空间，然后把它们拼接起来得到一个更大的词向量作为神经网络的输入，'输出'的是p(w_m)- 优点： 1、词语之间的相似性可以通过词向量来体现 2、自带平滑功能 [1.4] rnnlm:循环神经网络语言模型123456789101112- rnnlm特点：可以存在有向环，将上一次的输出作为本次的输入。- rnnlm和ffnnlm的最大区别是：ffnnmm要求输入的上下文是固定长度的，也就是说n-gram中的 n要求是个固定值，而rnnlm不限制上下文的长度，可以真正充分地利用所有上文信息来预测下一个词，本次预测的中间隐层信息(例如下图中的context信息)可以在下一次预测里循环使用。- 基本结构： 1、输入层： 2、隐藏层： 3、输出层：- 预测步骤： 1、单词w_&#123;m-1&#125;映射到词向量，记作input(t) 2、连接上一次训练的隐藏层context(t–1)，经过sigmoid function，生成当前t时刻的context(t) 3、利用softmax function，预测P(w_m)- 缺点：基于RNN的语言模型利用BPTT(BackPropagation through time)算法比较难于训练，原因就是深度神经网络里比较普遍的梯度消失问题。- 优点：训练精度高 [1.5] lstmlm:长短记忆神经网络123- lstmlm特点： 1、也是一种RNN网络，通过结构的修改避免了梯度消失。 2、能够记忆更多的信息。 2、N-gram的基本原理 N-gram即N元语法模型，采用马尔科夫假设，认为一个词生成的概率取决于他前面的N-1个词。 123456789- 约定： s:代表句子 w_i:第i个词 w_n:代表第n个词 N:词数- 句子s生成的概率如下： P(s) = p(w_1)p(w_2)p(w_3)...p(w_n)- \"为了避免数据溢出、提高性能，通常会使用取 log 后使用加法运算替代乘法运算\"即：- log(p(s)) = log(p(w_1))+log(p(w_2))+log(p(w_3))...log(p(w_n)) [2.1]、bigram:假设一个词生成的概率、取决于他前面1个词 12345678910- 句子s生成的概率如下： P(s) = p(w_1)p(w_2)p(w_3)...p(w_n)- bigram下词w_m生成的概率： p(w_1) = p(w_1) p(w_2) = p(w_2|w_1) p(w_3) = p(w_3|w_2) ... p(w_m) = p(w_m|w_m-1)- 得到句子生成的概率： P(s) = p(w_1)p(w_2|w_1)p(w_3|w_2)..p(w_m|w_m-1)..p(w_n|w_n-1)- [2.2]、trigram:假设一个词的生成概率取决于他前面的2个词 12345678910- 句子s生成的概率如下： P(s) = p(w_1)p(w_2)p(w_3)...p(w_n)- trigram下词w_m生成的概率： p(w_1) = p(w_1) p(w_2) = p(w_2|w_1) p(w_3) = p(w_3|w_&#123;1,2&#125;) ... p(w_m) = p(w_m|w_&#123;m-2,m-1&#125;)- 得到句子生成的概率： P(s) = p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)..p(w_m|w_m-2,w_m-1)..p(w_n|w_n-1,w_n-2)- 如上知道了如何去计算一个句子生成的概率，那么该如何去算其中的每一项呢？其实不过还是频率来表示概率。 bigram中P(w_m) = p(w_m|w_m-1)=count(w_m,w_m-1)/count(w_m-1)即计算当前词的概率用当前词和前一个词共同出现的次数比上前一个词出现的次数。 [2.3] bigram示例： 1234- 语料： s1：我喜欢西红柿炒鸡蛋 s2：西红柿是我最爱 s3: 我喜欢什么 单词词频： word 我 喜欢 西红柿 炒 鸡蛋 是 最爱 什么 count 2 2 1 1 1 1 1 1 p(word) 0.2 0.2 0.1 0.1 0.1 0.1 0.1 0.1 1234- 句子s1出现的概率： p(s1) = p(我)p(喜欢)p(西红柿)p(炒)p(鸡蛋) = p(我)p(喜欢|我)p(西红柿|喜欢)p(炒|西红柿)p(鸡蛋|炒)- 根据顺序共现得到bigram的共现词频如下： 顺序共现词频： word 我 喜欢 西红柿 炒 鸡蛋 是 最爱 什么 我 2 1 喜欢 1 1 西红柿 1 1 炒 1 鸡蛋 是 1 最爱 什么 1234567- 最后得到句子s1的概率如下： p(s1) = p(我)p(喜欢)p(西红柿)p(炒)p(鸡蛋) = p(我)p(喜欢|我)p(西红柿|喜欢)p(炒|西红柿)p(鸡蛋|炒) = 0.2 * (count(我喜欢)/count(我)) * (count(喜欢西红柿)/count(喜欢)) * (count(西红柿炒)/count(西红柿)) * (count(炒鸡蛋)/count(炒)) 同理可得trigram，n-gram的计算方式，分别去统计N元词出现的次数。得到条件概率。 [2.4]、数据平滑 123456- 数据平滑：大规模数据统计方法与有限的训练语料之间必然产生数据稀疏问题，导致零概率问题。为了解决数据稀疏问题，人们为理论模型实用化而进行了众多尝试与努力，诞生了一系列经典的平滑技术。- 基本思想：“降低已出现 n-gram 的条件概率分布，以使未出现的 n-gram 条件概率分布非零”，且经数据平滑后一定保证概率和为1，- 平滑技术： 1、加一平滑：又称拉普拉斯平滑 Pmle(w_m|w_m-1) = count(w_m,w_m-1)/count(w_m-1) Padd1(w_m|w_m-1) = count(w_m,w_m-1)+1/count(w_m-1)+VV代表2元词型的个数。V个二元词型保证概率和为1。 3、向量化12345678文本的向量化主要有以下几种： [1] countvec：词袋模型，词频表示 [2] Tf-idf：基于bow的权重表示 [3] 主题模型:PLSA，LDA [4] 词嵌入：word2vec,glove,fastext约定： 1、词袋：数据集中所有的的词构成的词集或词典。 2、词频：一篇文档中某个词出现的次数 1、词频向量：countvec12345- 定义：把每一篇文档表示为一个长度为词袋大小的向量，向量的每一个维度表示为词袋中的每一个词在此文档中出现的次数。- 优缺点： 1、能够一定程度反映词频信息，但是对于多篇文档中都出现的高频词没有银锭的区分度， 2、词袋模型向量大多是高维稀疏矩阵。 2、权重向量：tf-idf123456789- 定义：词频(TF)x逆文档词频(IDF)用于表示一个词的权重。- 优点： 1、降低多个文档都出现的高频词汇对重要度的影响。 2、提升低频词汇的重要度。 3、tf-idf+'N-gram'特征一定程度能够反映语序特征- 缺点： 1、权重向量也是高维稀疏矩阵. 2、不能完全反映语序信息 3、不能体现词语间的相似度信息。 3、主题向量：plsa,lda12345678- 定义：通过引入隐变量'主题'将词频向量或者权重向量映射到一个固定维度的稠密向量。- 优点： 1、降维作用，降低了模型的复杂度和计算量。 2、包含了一定的语义信息。- 缺点： 1、主题数难以确定。 2、主题作为一种概率分布表示，难以表述其具体含义，可解释性较差。 3、数据量大的时候主题训练耗时较长。 4、词嵌入向量:word2vec,glove,fasttext12345678- 定义：通过训练将每一个词映射到固定长度的词向量空间中，每个词就是一个点，同时引入距离的概念，就可以描述词语的相似度。- 优点： 1、考虑到了词语的相似度信息。 2、维度固定且低维，便于后续计算。 3、自带平滑功能- 缺点： 1、好的词向量表示依赖于足够的训练预料，尤其是领域性较强的文本依赖于相关的领域文本，否则可能得不到足够好的词向量。 2、词向量的训练需要额外的步骤。且大语料的训练耗时。 Word2Vec12345678910- 模型结构： |--&gt;输入层 |--&gt;隐藏层 |--&gt;softmax- 两种实现方式： 1、cbow 2、skip-gram- 两种优化方式： 1、层次化softmax 2、负采样 🐱目标函数： 123- w:词w- C:语料库- Context(w):词w的上下文信息 cbow:p(w|Context(w))：上下文词出现的情况下，词w出现的概率，即共现的概率。也是优化的目标，最大化这个概率。那么对与整个语料来说，目标函数就是最大化如下的概率积 $$L = \\prod_{w\\epsilon C}p(w|Context(w))$$ skip-gram:以当前词预测上下文词的概率，即目标函数就是最大化当前词出现的时候上下文词出现的概率积。 $$L = \\prod_{w\\epsilon C}p(Context(w)|w)$$ 最大对数似然： $$L = \\sum_{w\\epsilon C}log(p(w|Cotext(w))))$$ $$L = \\sum_{w\\epsilon C}log(p(Context(w)|w))$$ 1234- 训练过程： 1、输入层：随机初始化w的context(w)的每一个词(前后各c个)的词向量V(w)。 2、投影层：将词w的context(w)的所有V(w)求和。 3、输出层：层次化softmax层，一颗二叉树，用计算得到的输出每个词的概率。","categories":[{"name":"ML","slug":"ML","permalink":"http://nextnight.github.io/categories/ML/"},{"name":"NLP","slug":"ML/NLP","permalink":"http://nextnight.github.io/categories/ML/NLP/"}],"tags":[{"name":"分词","slug":"分词","permalink":"http://nextnight.github.io/tags/分词/"},{"name":"向量化","slug":"向量化","permalink":"http://nextnight.github.io/tags/向量化/"}]},{"title":"mac jupyter中文显示设置","slug":"Mac-jupyter中文显示设置","date":"2018-09-13T15:08:34.000Z","updated":"2018-09-29T07:12:29.467Z","comments":true,"path":"2018/09/13/Mac-jupyter中文显示设置/","link":"","permalink":"http://nextnight.github.io/2018/09/13/Mac-jupyter中文显示设置/","excerpt":"","text":"MAC-Jupyter使用matplotlib时设置中文123456789import matplotlib as mplimport matplotlib.pyplot as pltfrom matplotlib.font_manager import _rebuild_rebuild()%matplotlib inline# 设置中文显示mpl.rcParams['font.family']=['Microsoft Yahei']","categories":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/categories/Python/"}],"tags":[{"name":"Jupyter","slug":"Jupyter","permalink":"http://nextnight.github.io/tags/Jupyter/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://nextnight.github.io/tags/matplotlib/"}]},{"title":"Pandas基本操作","slug":"Pandas基本操作","date":"2018-09-13T14:58:52.000Z","updated":"2018-09-19T01:51:49.094Z","comments":true,"path":"2018/09/13/Pandas基本操作/","link":"","permalink":"http://nextnight.github.io/2018/09/13/Pandas基本操作/","excerpt":"","text":"Pandas 操作分类 基本设置 数据描述 数据清洗 数据索引 数据连接 分组聚合 文本操作 基本设置① ：设置不使用科学计数法，保留5位小数1pd.set_option('display.float_format', lambda x: '%.5f' % x) ② : 设置显示结果的宽度(不截断换行)1pd.set_option('display.width', 1000) 数据读取123456pd.read_csv()pd.read_table()pd.read_excle()pd.read_html()pd.read_json()pd.read_sql() 数据描述12import pandas as pddf = pd.read_csv(\"path\") ①：查看数据属性12345678# \b查看属性df.shapedf.indexdf.columnsdf.size# 去除格式，获取数据数组df.values ②：查看数据信息12345678910111213# 数据信息df.head(n) # 查看前n行df.tail(n) # 查看尾n行# 查看数据信息df.info()# 查看数据描述：df.describe() # 所有列描述df['col_name'].describe()# 某一列描述# 统计某列每个值的量:默认会从大到小排序df['clo_name'].value_counts(sort=True,ascending=False,bins=None,dropna=False) 数据索引索引设置123456789101112131415\"\"\"index,索引操作 1、set_index() 2、reset_index() 3、rename()\"\"\"# 设置索引df.set_index('A') # 设置列A为索引列# 重置索引:恢复默认的自增索引df.reset_index(inplace=True) # 设置inplace的时候会修改原始df,并且没有返回值df = df.reset_index() # 不设置inplace=True需接受返回值，且原始df不变df.rename(index=lambda x:x+1)# 所有索引值+1\"\"\"修改列名\"\"\"df.rename(&#123;\"A\":\"AAAAA\",\"B\":\"BBBB\"&#125;,inplace=True) # 把A修改成AAAAAdf.rename(columns=lambda x: x + 2) # 将全体列重命名 索引数据12345678910111213\"\"\"直接列索引：\"\"\"df[1] # 第一列df['Q'] #Q列\"\"\"\"行索引： 1、iloc 2、loc 3、ix\"\"\"\"df.loc[df['Q']=0] # 索引满足Q=0的虽偶有行数据df.loc[(df['Q'] &amp; df['T']=1)]df.loc[(df['Q'] &amp; df['T']=1) 'x'] = -1 # 满足条件的所有行数据给X 列赋值为-1 数据清洗数据缺失处理12345678910111213141516171819202122232425\"\"\"判断缺失: 1、isnull(), 2、isna()\"\"\"df.isnull() # 返回每个数据是否是nulldf.isna() # 返回每个数据是否是na\"\"\"缺失填充: 1、fillna(), 2、ffill(), 3、bfill()\"\"\"df.ffill()df.bfill()df.fillna(0)\"\"\"缺失删除:dropna()param: axis:1,0 axis=1 删除含有na的列,axis=0 删除含有na的行, how:any,all how='any'表示某列所有行存在为null即删除,how='all'，表示某行所有列都为null才删除 subset:选择子集 inplace:是否覆盖原数据\"\"\"df = df.dropna(self, axis=0, how='any', thresh=None, subset=None,inplace=False)df.dropna(self, axis=1, how='all', thresh=None, subset=['col1','col2'],inplace=True) 数据异常处理123456789101112131415161718\"\"\"数据删除:drop()param: axis:0,1 分别对应indexs,columns\"\"\"df.drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')df.drop(['a','b'],axis=1,inplace=True) # 删除a，b列df.drop([0,1],axis=0,inplace=True) # 删除0，1行\"\"\"数据删除：del\"\"\"del df['A'] # 删除A列\"\"\"\b数值替换:replace()\"\"\"df.replace([1,3],['one','three']) # 1替换成one,3替换成threedf.rename(&#123;1:'one',3:'three'&#125;) 数据过滤,选择12345df[(df['age']&gt;10) &amp; (df['age']&lt;40) ]df.loc[(df['age']&gt;10) &amp; (df['age']&lt;40) ]df[df['age']==20]df[df['age'].isin([2,3,5]) ] 数据排序123\"\"\"排序：sort_values(by='column',inplace=None,acsending=True) \"\"\"df.sort_values(by='',inplace=True,acsending=False) # acsending=False 从大到小 数据编码123\"\"\"one_hot:get_dummies()\"\"\"\"dt_one_hot = pd.get_dummies(dt[['A','B']]) # 对A，B 列进行onehot编码 数据分箱123\"\"\"df.cut()\"\"\"df_col1 = pd.cut(df['column1'], bins=[0, 0.5, 0.8, 2, 20, 1000], labels=np.arange(1, 6, 1))","categories":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/categories/Python/"},{"name":"Pandas","slug":"Python/Pandas","permalink":"http://nextnight.github.io/categories/Python/Pandas/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/tags/Python/"},{"name":"Pandas","slug":"Pandas","permalink":"http://nextnight.github.io/tags/Pandas/"}]},{"title":"Numpy基本操作","slug":"Numpy基本操作","date":"2018-09-10T14:45:39.000Z","updated":"2018-09-15T02:25:03.415Z","comments":true,"path":"2018/09/10/Numpy基本操作/","link":"","permalink":"http://nextnight.github.io/2018/09/10/Numpy基本操作/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import numpy as np\"\"\"numpy的基本应用1、四个属性 ndim:获取数据的维度数 shape:收取数据的维度 dtype:获取数据的类型 size:2、N个方法 1、zeros,ones,empty,arange 2、max,min,std,mean,sum,var,median,cumsum 3、astype,reshape 4、argmax,argmin,argsort 5、all,any,fill,where，diff 6、vstack,hstack 7、unique 8、load,save:操作文件 9、insert,arange,reshape 10、bincount\"\"\"def numpy_filed(): ll = np.array([[1, 2, 3, 5, 6], [2, 3, 4, 5, 7]]) print(ll) print(ll.ndim) # 2；表示2个维度 print(ll.shape) # (5,):表示五个元素 print(ll.dtype) # 元素类型int64:表示数据类型 print(ll.size) # 10：元素个数 print(type(ll)) # 对象类型&lt;class 'numpy.ndarray'&gt;def numpy_method(): \"\"\" max,min,std,mean,sum,var,median,cumsum astype:转换数据类型 argmax,argmin,argsort all,any,fill,where vstack,hstack load,save:操作文件 insert,arange,reshape \"\"\" ll = np.array([[1, 4, 3, 5, 6], [2, 3, 4, 5, 7]]) # max,min,std,mean,sum,var,median,cumsum print(ll.max()) # 全局最大值 print(ll.max(axis=1)) # axis=1：行最大值 [6 7] print(ll.max(axis=0)) # axis=0 列最大 [2 4 4 5 7] print(ll.cumsum()) # 前所有项的和组成的序列 # astype: 转换数据类型 ll = ll.astype(dtype=np.float64) print(ll.dtype) # float64 # argmax, argmin, argsort print(ll.argmax(axis=1)) # axis=1 返回每行的最大数值的索引[4,4] print(ll.argmin(axis=0)) # axis=0 返回每列的最小值的索引 [1 1 1 0 1] print(ll.argsort(axis=0))# 按行排序返回排序后的索引，未指定排序的列，就是返回所有的列排序的结果 # all,any,fill,where，diff # all()全部满足条件，any()存在满足条件的 # vstack,hstack p1 = np.zeros((3,3)) p2 = np.ones((3,3)) print(\"纵向叠加：\\n\",np.vstack((p1,p2))) # 数据拼接，维度不变 print(\"横向叠加：\\n\",np.hstack((p1,p2))) # 数据连接，行数不变 # unique：找出唯一值并返回排序后的结果 print(np.unique(ll)) # [1. 2. 3. 4. 5. 6. 7.]if __name__ == '__main__': numpy_filed() numpy_method()","categories":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/categories/Python/"},{"name":"Numpy","slug":"Python/Numpy","permalink":"http://nextnight.github.io/categories/Python/Numpy/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"http://nextnight.github.io/tags/Numpy/"}]},{"title":"Python代码片段","slug":"Python代码片段","date":"2018-09-10T14:03:51.000Z","updated":"2018-09-29T07:25:46.051Z","comments":true,"path":"2018/09/10/Python代码片段/","link":"","permalink":"http://nextnight.github.io/2018/09/10/Python代码片段/","excerpt":"","text":"1、多变量赋值1a, b, c, d = 0, 1, 2, 3 2、列表赋值12names = [\"ami\", \"kimi\", \"jsm\"]a, b, c = names 3、条件表达式12x = 8d = x if x &gt; 5 else 10 4、列表推导式1a = [i for i in range(1000) if i % 2 == 0] 5、条件判断:不是用and12x = 90if 80 &lt; x &lt; 100: print(x) 6、判断是否在/不在某列表,字符串12345if 1 in [1, 2, 3]: print(1)if 1 not in [1, 2, 3]: print(0)if '1' in \"123\": print(2)if '1' not in \"123\": print(2) 7、隐含类型转换判空123456789a, b, c, d = [1, 2, 3], &#123;&#125;, '', []if a: print(\"a not empty\")if b: print(\"b not empty\")if c: print(\"c not empty\")if d: print(\"d not empty\") 8、判断多个条件是否成立:any，all123a, b, c = 1, 2, 3if any([a &gt; 1, b &lt; 2, c == 3]): pass # === a&gt;1 or b&lt;2 or c==3if all([a &gt; 1, b &lt; 2, c == 3]): pass # === a&gt;1 and b&lt;2 and c==3 9、列表推导式+过滤123ls = [1, 2, 3, \"a\", 4, \"v\", 5.5]rs = [i for i in ls if type(i) in [int, float]]print(rs) 10、同时获取下标和数据：enumerate123nums = [1, 2, 3, 4]for index, num in enumerate(nums): print(\"索引为&#123;&#125;的数据是&#123;&#125;\".format(index, num)) 11、线程sleep123import timetime.sleep(1) # 休眠1秒 12、print 输出覆盖1234i, n = 0, 100for i in range(n): time.sleep(0.1) if (i + 1) % 10 == 0: print(i + 1, end = '\\r') 13、lambda匿名函数123names = ['a', 'b', 'xxx', 'vx', 'ccc']rs = filter(lambda x:len(x) &lt;= 1, names)print(list(rs)) # ['a', 'b'] 14、yield生成器收集系列值，不需要return1234567def fun(): a = 0 for i in range(10): a += i yield a# [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]print(list(fun())) 15、装饰器给函数添加插入日志，性能测试等非核心功能12345678910111213141516def runtime(func): def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(\"&#123;&#125; is called,used &#123;&#125;s.\".format(func.__name__, start - end)) return result return (wrapper)@runtimedef process(): s = 0 for i in range(100): time.sleep(1) s += iprocess() 16、内存拷贝使用：copy包中的copy()函数和deepcopy()函数 16.1：赋值：指向同一块地址 1234a = &#123;1: [1, 2, 3]&#125;print('a的内存地址 %s' % id(a)) # 4386109840print('a1的内存地址 %s' % id(a[1])) # 4391711560b = a 16.2：浅拷贝：指向不同的引用，但是不同引用指向相同内容(只拷贝对象，但不拷贝对象内部的对象) 12345b = copy.copy(a)print('a的内存地址 %s' % id(a)) # 4386109840print('b的内存地址 %s' % id(b)) # 4386110200print('a1的内存地址 %s' % id(a[1])) # 4391711560print('b1的内存地址 %s' % id(b[1])) # 4391711560 16.3：深拷贝：对象及对象内部的对象都复制一份 12345b = copy.deepcopy(a)print('a的内存地址 %s' % id(a)) # 4386109840print('b的内存地址 %s' % id(b)) # 4391729264print('a1的内存地址 %s' % id(a[1])) # 4391711560print('b1的内存地址 %s' % id(b[1])) # 4391711368 17、参数传递","categories":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://nextnight.github.io/tags/Python/"}]},{"title":"数据结构与算法","slug":"数据结构与算法","date":"2018-08-14T03:57:08.000Z","updated":"2018-08-27T06:56:00.076Z","comments":true,"path":"2018/08/14/数据结构与算法/","link":"","permalink":"http://nextnight.github.io/2018/08/14/数据结构与算法/","excerpt":"","text":"是时候沉下心来学习一波数据结构与算法了，好的算法能够轻松的而解决各种难题，而好的数据结构是实现算法的前提，算法设计依托与不同的数据结构，同样，算法也是解决不同形式的数据问题。计划步骤： 1、深入操作基本数据结构 2、深入\b回顾基础算法 3、深入理解基本算法思想 4、算法刷题，书籍阅读 算法思想 递归 穷举 递推 贪心 回溯 分治 动态规划 数据结构 数组 链表 栈 队列 字符串 🌲树 trie树 哈希 图 基础算法排序 交换排序 选择排序 插入排序 冒泡排序 快速排序 堆排序 希尔排序 归并排序 线性排序 桶排序 查找 顺序查找 二分查找 分块查找 动态查找 二叉排序树 平衡二叉树 B树，B+树 Hash查找 经典算法 快速排序 BFS/DFS KMP A*寻路 Dijkstra 遗传算法 动态规划 海量数据处理 Hash Bitmap Bloom filter Trie树 Index Inverted Index simhash","categories":[{"name":"算法","slug":"算法","permalink":"http://nextnight.github.io/categories/算法/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://nextnight.github.io/tags/数据结构/"},{"name":"算法","slug":"算法","permalink":"http://nextnight.github.io/tags/算法/"}]},{"title":"LeetCode-Array","slug":"\b\bLeetCode-Array","date":"2018-07-31T15:21:37.000Z","updated":"2018-09-29T07:29:57.847Z","comments":true,"path":"2018/07/31/\b\bLeetCode-Array/","link":"","permalink":"http://nextnight.github.io/2018/07/31/\b\bLeetCode-Array/","excerpt":"","text":"整数求和1234567891011def a_num_sum(num): \"\"\"整数各位之和：2018-07-31\"\"\" \"\"\" Q: 给一个非负整数，求每一位的数字加和，得到之后的数字在把每一位进行加和，直到结果为一位数 E: 比如：83-&gt;8+3=11-&gt;1+1=2,输出2 case: 尾递归，进入下一层不再需要上一层的环境，因为这个递归完成后不再需要干其他的事，所以直接return这个递归，就会得到最内层的结果 \"\"\" if num &lt; 10: return num if num &gt;= 10: return a_num_sum(sum([int(i) for i in list(str(num))])) # 没有return就不是一个尾递归，返回结果为none 12345# 如果要输出每次计算的值print(num) # 83 11 2if num &gt;= 10: a_num_sum(sum([int(i) for i in list(str(num))]))print(num) # 2,11,83 求两数之和等与目标值基础暴力解法12345678910111213def two_sum(dt, tag): \"\"\"整数翻转：2018-07-31\"\"\" \"\"\" Q:给定一个整数数组和一个目标值，找出数组中和为目标值的两个数。你可以假设每个输入只对应一种答案，且同样的元素不能被重复利用。 E:[2,7,3,11] tag:9 R:[0,1] E:[3,3] tag:6 R:[0,1] \"\"\" for i,it in enumerate(dt): for j,jt in enumerate(dt): if it+jt==tag and i!=j: return [i,j] 以下解法同上：看上去没那么高复杂度，其实是一样的。123for i, item in enumerate(dt): if (tag - item) in dt and dt.index(tag - item)!=i: return [i, dt.index(tag - item)] 遍历一遍数组解法123456789101112//hashmap，dict解法，public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement)) &#123; return new int[] &#123; map.get(complement), i &#125;; &#125; map.put(nums[i], i); &#125; throw new IllegalArgumentException(\"No two sum solution\");&#125; 整数翻转123456789101112131415def reverse(num): \"\"\"整数翻转：2018-08-01\"\"\" \"\"\" Q:给定一个 32 位有符号整数，将整数中的数字进行反转。假设我们的环境只能存储 32 位有符号整数， 其数值范围是 [−2**31, 2**31 − 1]。根据这个假设，如果反转后的整数溢出，则返回 0。 \"\"\" sum = 0 while True: lens = len(str(num)) - 1 sum += (num % 10) * 10**lens num = int(num/10) if lens==0: if sum&lt;-2**31 or sum&gt;2**31-1: return 0 return sum 数组中子序列最大和1234567891011121314151617181920def max_sum_subarry(nums): \"\"\"子串最大和:2018-08-02\"\"\" \"\"\" Q:给定一个数组求其子数组和最大的值。 E:[1, -2, 3, 10, -4, 7, 2, -5] R:[3,10,-4,7,2]=18 trick: 动态规划 \"\"\" if nums is None: return None if len(nums) == 1: return nums[0] sum = nums[0] # 第i-1个数的最大序列和 cur = nums[0] # 第i个数的最大序列和 for i, it in enumerate(nums[1:]): cur = max(cur + it, it) # 状态方程：max(sum_i) = max(sum_i-1+num[i],num[i]) if sum &lt; cur: sum = cur return sum 数组中最大和的子序列1234567891011121314151617181920212223242526272829def max_subarray(nums): \"\"\"最大和的子串:2018-08-03\"\"\" \"\"\" Q:给定一个数组求其子数组和最大的值。 E:[1, -2, 3, 10, -4, 7, 2, -5] R:[3,10,-4,7,2]=18 trick: 动态规划 \"\"\" if nums is None: return 0 if len(nums) == 1: return nums[0] sum = nums[0] # 第i-1个数的最大序列和 cur = nums[0] # 第i个数的最大序列和 maxls = [nums[0]] # 用于和最大的子序列 for i, it in enumerate(nums[1:]): # cur = max(cur + it, it) # 状态方程：max(sum_i) = max(sum_i-1+num[i],num[i]) if cur + it &gt;= it: cur = cur + it maxls.append(it) else: cur = it maxls = [it] if sum &lt; cur: sum = cur # 去掉子序列尾部的负数 while maxls[-1] &lt; 0: maxls.pop(-1) return sum,maxls 股票的最大利润①🦁 link:Leetcode🐇 思路：记录最小值，和最大利润，不断用当前值-最小值去计算利润，如果大于最大利润则更新。保证当前值永远在最小值之后，因为卖出时间必须晚于或等于买入时间。1234567891011121314151617181920def max_stock(nums): \"\"\"股票最大利润-最多购买一次：2018-08-04\"\"\" \"\"\" A: 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票）， 设计一个算法来计算你所能获取的最大利润 E:[7,1,5,3,6,4] R:[1,6] = 5 E:[7,6,4,3,1] R:0 \"\"\" if len(nums) == 1 or nums==None: return 0 mins = nums[0] stock = 0 for it in nums[1:]: mins = min(it,mins) stock = max(it-mins,stock) return stock 股票的最大利润②🦁 link:Leetcode🐇 思路：找到所有的上升区域，每个区域的差值之和就是总利润。123456789101112131415def max_stock_all(nums): \"\"\"股票最大利润-购买多次不限次数：：2018-08-05\"\"\" \"\"\" E:[7,1,5,3,6,4] R:5-1+6-3=7 \"\"\" if len(nums)==1 or nums==None: return 0 stock = 0 min = nums[0] for it in nums[1:]: if it&gt;min: stock +=it-min min = it return stock 股票购买最大利润③🦁link:🐇思路：12345def max_stock_two(): \"\"\"股票最大利润-购买次数为2：：2018-08-06\"\"\" \"\"\" \"\"\" pass 矩阵转置🦁link:Leetcode🐇思路：二维数组每一个元素的下标i行，j列变j行i列，即a[j][i] =a[i][j]1234567891011121314def transpose(A): \"\"\"转置矩阵:2018-08-07\"\"\" \"\"\" E:[[1,2,3],[4,5,6]] R:[[1,4],[2,5],[3,6]] \"\"\" # r行，c列 转置得到c行r列 r,c = len(A),len(A[0]) # 定义一个c,行r列的矩阵 rs = [ [None]*r for i in np.arange(c)] for r,row in enumerate(A): for c,it in enumerate(row): rs[c][r] = it return rs","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://nextnight.github.io/categories/Algorithm/"},{"name":"LeetCode","slug":"Algorithm/LeetCode","permalink":"http://nextnight.github.io/categories/Algorithm/LeetCode/"}],"tags":[{"name":"Array","slug":"Array","permalink":"http://nextnight.github.io/tags/Array/"}]},{"title":"不忘初心","slug":"不忘初心","date":"2018-07-30T14:16:33.000Z","updated":"2018-09-29T08:25:14.991Z","comments":true,"path":"2018/07/30/不忘初心/","link":"","permalink":"http://nextnight.github.io/2018/07/30/不忘初心/","excerpt":"","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)'],['\\\\','\\\\']]} }); 不忘初心，方得始终初心易守，始终难得 $$(\\frac12)(12)(12)$$ $$\\begin{matrix}1 &amp; x &amp; x^2 \\\\1 &amp; y &amp; y^2 \\\\1 &amp; z &amp; z^2 \\\\\\end{matrix}$$ $$\\frac { dy }{ dx } =\\frac { { e }^{ x } }{ 3{ y }^{ 2 } }$$ $$\\lim_{ x\\rightarrow \\infty }{ \\sum_{ k=1 }^{ x }{ \\frac { \\sin { k } +\\cos { k } }{ k } } } $$ $$H=-\\sum_{i=1}^N (\\sigma_{i}^x \\sigma_{i+1}^x+g \\sigma_{i}^z)$$ $$f(n) = \\begin{cases} \\frac{n}{2}, &amp; \\text{if } n\\text{ is even}\\\\ 3n+1, &amp; \\text{if } n\\text{ is odd} \\end{cases}$$ $f(x)=ax+b$ $$\\left \\lbrace \\sum_{i=0}^n i^3 = \\frac{(n^2+n)(n+6)}{9} \\right \\rbrace$$$$ \\lbrace \\sum_{i=0}^n i^3 = \\frac{(n^2+n)(n+6)}{9} \\rbrace$$$\\frac xy$$ x+3 \\over y+5 $","categories":[{"name":"Test","slug":"Test","permalink":"http://nextnight.github.io/categories/Test/"}],"tags":[{"name":"Test","slug":"Test","permalink":"http://nextnight.github.io/tags/Test/"}]}]}